{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e388569",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ‚Äì ASSIGNMENT 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ca0c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\shaik\\anaconda3\\lib\\site-packages (4.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: websocket-client>=1.8.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from selenium) (0.26.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f024a0",
   "metadata": {},
   "source": [
    "# Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and \n",
    "salary filter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718699a",
   "metadata": {},
   "source": [
    "1. first get the web page https://www.naukri.com/ \n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.  \n",
    "3. Then click the search button.  \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes  \n",
    "5. Then scrape the data for the first 10 jobs results you get.  \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c24c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a3ed95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrom browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b46c755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get web page\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "489704ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search inputs Data scientist\n",
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4f04b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click search button\n",
    "search_button=driver.find_elements(By.CLASS_NAME,'qsbSubmit')\n",
    "for button in search_button:\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db908587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use filter here \n",
    "time.sleep(3)\n",
    "salaries = driver.find_elements(By.XPATH, '//*[text()=\"3-6 Lakhs\"][1]')\n",
    "for s in salaries:\n",
    "    s.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1f0f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use filter on location\n",
    "locations = driver.find_elements(By.XPATH, '//*[text()=\"Delhi / NCR\"][1]')\n",
    "for i in locations:\n",
    "    i.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b904c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title  = driver.find_elements(By.XPATH , '//div[@class=\" row1\"]')\n",
    "location  = driver.find_elements(By.XPATH , '//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "exp_years = driver.find_elements(By.XPATH , '//span[@class=\"exp-wrap\"]')\n",
    "company = driver.find_elements(By.XPATH , '//span[@class=\" comp-dtls-wrap\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f86d016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_list=[]\n",
    "location_list=[]\n",
    "years_list=[]\n",
    "company_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6296e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', 'Data Scientist III', 'Data Scientist', 'Data Scientist', 'Data Scientist', '', '', '', 'Data Scientist', 'Data scientist']\n",
      "['Delhi / NCR, Pune, Bengaluru', 'Gurugram', 'Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru', 'New Delhi', 'Gurugram', 'Mumbai, Gurugram', 'Gurugram, Bengaluru', 'Gurugram', 'Noida', 'Noida']\n",
      "['6-11 Yrs', '2-6 Yrs', '2-5 Yrs', '0-2 Yrs', '1-5 Yrs', '', '', '', '0-5 Yrs', '0-1 Yrs']\n",
      "['Wipro\\n3.8\\n41422 Reviews', 'Flutter', 'Essenware\\n4.7\\n4 Reviews', 'Fortune 500 IT Services Company', 'Big 4 Consulting Firm', '', '', '', 'Sociomix', 'Growthjockey\\n4.1\\n6 Reviews']\n"
     ]
    }
   ],
   "source": [
    "for i in  range(10):\n",
    "    job_title_list.append(job_title[i].text)\n",
    "    location_list.append(location[i].text)\n",
    "    years_list.append(exp_years[i].text)\n",
    "    company_list.append(company[i].text)\n",
    "print(job_title_list)\n",
    "print(location_list)\n",
    "print(years_list)\n",
    "print(company_list)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea17c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title_list),len(location_list),len(years_list),len(company_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "079ca47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>loaction</th>\n",
       "      <th>Experience_needed</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Wipro\\n3.8\\n41422 Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Flutter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Essenware\\n4.7\\n4 Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Fortune 500 IT Services Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Big 4 Consulting Firm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Mumbai, Gurugram</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Gurugram</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Sociomix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Growthjockey\\n4.1\\n6 Reviews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_title                                           loaction  \\\n",
       "0      Data Scientist                       Delhi / NCR, Pune, Bengaluru   \n",
       "1  Data Scientist III                                           Gurugram   \n",
       "2      Data Scientist  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "3      Data Scientist                                          New Delhi   \n",
       "4      Data Scientist                                           Gurugram   \n",
       "5                                                       Mumbai, Gurugram   \n",
       "6                                                    Gurugram, Bengaluru   \n",
       "7                                                               Gurugram   \n",
       "8      Data Scientist                                              Noida   \n",
       "9      Data scientist                                              Noida   \n",
       "\n",
       "  Experience_needed                     company_name  \n",
       "0          6-11 Yrs        Wipro\\n3.8\\n41422 Reviews  \n",
       "1           2-6 Yrs                          Flutter  \n",
       "2           2-5 Yrs        Essenware\\n4.7\\n4 Reviews  \n",
       "3           0-2 Yrs  Fortune 500 IT Services Company  \n",
       "4           1-5 Yrs            Big 4 Consulting Firm  \n",
       "5                                                     \n",
       "6                                                     \n",
       "7                                                     \n",
       "8           0-5 Yrs                         Sociomix  \n",
       "9           0-1 Yrs     Growthjockey\\n4.1\\n6 Reviews  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making data frame\n",
    "dataframe = pd.DataFrame ({\n",
    "    'job_title':job_title_list,\n",
    "    'loaction':location_list,\n",
    "    'Experience_needed':years_list,\n",
    "    'company_name':company_list})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930e67e",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ceb658",
   "metadata": {},
   "source": [
    "1. First get the webpage https://www.shine.com/ \n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field. \n",
    "3. Then click the searchbutton.  \n",
    "4. Then scrape the data for the first 10 jobs results you get.  \n",
    "5. Finally create a dataframe of the scraped data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e6cc8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "                                   Job title  \\\n",
      "0                             Data Scientist   \n",
      "1                             Data Scientist   \n",
      "2                             Data Scientist   \n",
      "3                 Data Scientist Recruitment   \n",
      "4                             Data Scientist   \n",
      "5                  Hiring For Data Scientist   \n",
      "6                             Data Scientist   \n",
      "7                               Data Analyst   \n",
      "8  Senior Associate Data Engineering Level 2   \n",
      "9                            Hr Data Analyst   \n",
      "\n",
      "                            Coampany Name    Job Location     Experience  \n",
      "0      comosrich it & consulting services       Bangalore     3 to 8 Yrs  \n",
      "1       dotcod innovation private limited   Bangalore\\n+1     2 to 6 Yrs  \n",
      "2                     meraki it solutions       Bangalore     3 to 6 Yrs  \n",
      "3                       kavya interprises  Bangalore\\n+13     0 to 4 Yrs  \n",
      "4                      vaishnavi services  Bangalore\\n+10  18 to >25 Yrs  \n",
      "5               neelima staffing solution  Bangalore\\n+15     0 to 4 Yrs  \n",
      "6                      talent toppers llp   Bangalore\\n+2     0 to 3 Yrs  \n",
      "7                        aryan technology   Bangalore\\n+4     0 to 4 Yrs  \n",
      "8               tlg india private limited   Bangalore\\n+7     5 to 9 Yrs  \n",
      "9  leverage business solutions private...       Bangalore     4 to 8 Yrs  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Coampany Name</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>comosrich it &amp; consulting services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>dotcod innovation private limited</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>meraki it solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>vaishnavi services</td>\n",
       "      <td>Bangalore\\n+10</td>\n",
       "      <td>18 to &gt;25 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>neelima staffing solution</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>talent toppers llp</td>\n",
       "      <td>Bangalore\\n+2</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>aryan technology</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Associate Data Engineering Level 2</td>\n",
       "      <td>tlg india private limited</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hr Data Analyst</td>\n",
       "      <td>leverage business solutions private...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>4 to 8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job title  \\\n",
       "0                             Data Scientist   \n",
       "1                             Data Scientist   \n",
       "2                             Data Scientist   \n",
       "3                 Data Scientist Recruitment   \n",
       "4                             Data Scientist   \n",
       "5                  Hiring For Data Scientist   \n",
       "6                             Data Scientist   \n",
       "7                               Data Analyst   \n",
       "8  Senior Associate Data Engineering Level 2   \n",
       "9                            Hr Data Analyst   \n",
       "\n",
       "                            Coampany Name    Job Location     Experience  \n",
       "0      comosrich it & consulting services       Bangalore     3 to 8 Yrs  \n",
       "1       dotcod innovation private limited   Bangalore\\n+1     2 to 6 Yrs  \n",
       "2                     meraki it solutions       Bangalore     3 to 6 Yrs  \n",
       "3                       kavya interprises  Bangalore\\n+13     0 to 4 Yrs  \n",
       "4                      vaishnavi services  Bangalore\\n+10  18 to >25 Yrs  \n",
       "5               neelima staffing solution  Bangalore\\n+15     0 to 4 Yrs  \n",
       "6                      talent toppers llp   Bangalore\\n+2     0 to 3 Yrs  \n",
       "7                        aryan technology   Bangalore\\n+4     0 to 4 Yrs  \n",
       "8               tlg india private limited   Bangalore\\n+7     5 to 9 Yrs  \n",
       "9  leverage business solutions private...       Bangalore     4 to 8 Yrs  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "#open web browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#find the web page of shine\n",
    "driver.get('https://www.shine.com/')\n",
    "\n",
    "#click on search bar for give the input\n",
    "input_job_title= driver.find_elements(By.CLASS_NAME,\"input\")\n",
    "\n",
    "#search data analytics job Role\n",
    "input_job_title[0].send_keys('Data Scientist')\n",
    "\n",
    "#click search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"iconH-zoom-white\")\n",
    "search.click()\n",
    "\n",
    "# again search job designation\n",
    "# Wait for the job designation input field to be visible\n",
    "job_designation= WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, \"form-control\")))\n",
    "#search job Designation\n",
    "job_designation.send_keys('Data Scientist')\n",
    "\n",
    "#search location\n",
    "job_location=driver.find_elements(By.ID,\"id_loc\")\n",
    "#type location in searchj bar\n",
    "job_location[0].send_keys('Bangalore')\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'driver' is your WebDriver instance\n",
    "sarch = driver.find_elements(By.CSS_SELECTOR, \".btn.btn-secondary.undefined\")\n",
    "\n",
    "# Now sarch iterate with all elements\n",
    "for element in sarch:\n",
    "    element.click()\n",
    "    \n",
    "# create list for scrape the Data sceintist  data from shine web\n",
    "job_title=[]\n",
    "job_locations=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "# scrapping job title from, the given page \n",
    "title_tag=driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]')\n",
    "for i in title_tag:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "print(len(job_title))\n",
    "\n",
    "#scraping Company name\n",
    "company=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company:\n",
    "    comp=i.text\n",
    "    company_name.append(comp)\n",
    "print(len(company_name))\n",
    "\n",
    "\n",
    "#scraping Location\n",
    "location=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location:\n",
    "    loc=i.text\n",
    "    job_locations.append(loc)\n",
    "print(len(job_locations))\n",
    "\n",
    "\n",
    "#scraping Experience\n",
    "exp=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in exp:\n",
    "    experien=i.text\n",
    "    experience_required.append(experien)\n",
    "print(len(experience_required))\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "#create the Data Frame\n",
    "shiny_job_df=pd.DataFrame({'Job title':job_title[:10],'Coampany Name':company_name[:10],'Job Location':job_locations[:10],'Experience':experience_required[:10]})\n",
    "print(shiny_job_df)\n",
    "shiny_job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5bee00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f865690",
   "metadata": {},
   "source": [
    "# Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4f90d",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79ab59",
   "metadata": {},
   "source": [
    "1. Rating \n",
    "2. Review summary \n",
    "3. Full review \n",
    "4. You have to scrape this data for first 100reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2778eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product Rating         Short Review  \\\n",
      "0               5    Worth every penny   \n",
      "1               5  Best in the market!   \n",
      "2               5            Wonderful   \n",
      "3               5             Terrific   \n",
      "4               5            Just wow!   \n",
      "..            ...                  ...   \n",
      "95              5            Must buy!   \n",
      "96              5     Perfect product!   \n",
      "97              5       Classy product   \n",
      "98              5            Fabulous!   \n",
      "99              5    Terrific purchase   \n",
      "\n",
      "                                          Full Review  \n",
      "0   Feeling awesome after getting the delivery of ...  \n",
      "1                                         Good Camera  \n",
      "2                              This is amazing at all  \n",
      "3                                      Very very good  \n",
      "4                                   Perfect Product!!  \n",
      "..                                                ...  \n",
      "95                                It‚Äôs really awesome  \n",
      "96                                       Photos super  \n",
      "97  Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "98  It‚Äôs very good battery life and display and vi...  \n",
      "99                                  Value for money üòç  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Rating</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It‚Äôs really awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>It‚Äôs very good battery life and display and vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üòç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product Rating         Short Review  \\\n",
       "0               5    Worth every penny   \n",
       "1               5  Best in the market!   \n",
       "2               5            Wonderful   \n",
       "3               5             Terrific   \n",
       "4               5            Just wow!   \n",
       "..            ...                  ...   \n",
       "95              5            Must buy!   \n",
       "96              5     Perfect product!   \n",
       "97              5       Classy product   \n",
       "98              5            Fabulous!   \n",
       "99              5    Terrific purchase   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Feeling awesome after getting the delivery of ...  \n",
       "1                                         Good Camera  \n",
       "2                              This is amazing at all  \n",
       "3                                      Very very good  \n",
       "4                                   Perfect Product!!  \n",
       "..                                                ...  \n",
       "95                                It‚Äôs really awesome  \n",
       "96                                       Photos super  \n",
       "97  Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "98  It‚Äôs very good battery life and display and vi...  \n",
       "99                                  Value for money üòç  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open browser\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# get web page of flipkart\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART')\n",
    "\n",
    "# scrape data of Product\n",
    "rat = driver.find_elements(By.XPATH, '//div[@class=\"XQDdHH Ga3i8K\"]')\n",
    "rev = driver.find_elements(By.XPATH, '//p[@class=\"z9E0IG\"]')\n",
    "ful_rev = driver.find_elements(By.XPATH, '//div[@class=\"ZmyHeo\"]')\n",
    "time.sleep(3)\n",
    "\n",
    "# making list\n",
    "rating = []\n",
    "review = []\n",
    "full_review = []\n",
    "\n",
    "# SCRAPE 100 REVIEWS DATA\n",
    "start = 1\n",
    "end = 11\n",
    "for page in range(start, end):\n",
    "    rat = driver.find_elements(By.XPATH, '//div[@class=\"XQDdHH Ga3i8K\"]')\n",
    "    rev = driver.find_elements(By.XPATH, '//p[@class=\"z9E0IG\"]')\n",
    "    ful_rev = driver.find_elements(By.XPATH, '//div[@class=\"ZmyHeo\"]')\n",
    "    \n",
    "    for i in range(len(rat)):  # Iterate over the elements found on the page\n",
    "        rating.append(rat[i].text)\n",
    "        review.append(rev[i].text)\n",
    "        full_review.append(ful_rev[i].text)\n",
    "\n",
    "# making Data Frame\n",
    "Reviews_data = pd.DataFrame({\n",
    "    \"Product Rating\": rating,\n",
    "    \"Short Review\": review,\n",
    "    \"Full Review\": full_review\n",
    "})\n",
    "driver.quit()\n",
    "print(Reviews_data)\n",
    "Reviews_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df248ebc",
   "metadata": {},
   "source": [
    "# Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search field. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759cdb1",
   "metadata": {},
   "source": [
    "You have to scrape 3 attributes of each sneaker: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a6f7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Brand name                                Sneaker Description  \\\n",
      "0             BRUTON  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...   \n",
      "1               aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...   \n",
      "2          Deals4you                                   Sneakers For Men   \n",
      "3               aadi                                   Sneakers For Men   \n",
      "4    U.S. POLO ASSN.  Lightweight Comfort Summer Trendy Premium Styl...   \n",
      "..               ...                                                ...   \n",
      "121             PUMA                                   Sneakers For Men   \n",
      "122         JUMPLITE  ( by GO21 ) Soft Insole, Slip-Resistance|Chunk...   \n",
      "123            Zixer  Kook N Keech Men White Faux Leather CASUAL Lac...   \n",
      "124             PUMA  Trending Stylish Casual Outdoor Shoes Sneakers...   \n",
      "125             PUMA               Dexster Slip On IDP Sneakers For Men   \n",
      "\n",
      "      Price  \n",
      "0      ‚Çπ297  \n",
      "1      ‚Çπ299  \n",
      "2      ‚Çπ399  \n",
      "3      ‚Çπ299  \n",
      "4    ‚Çπ1,249  \n",
      "..      ...  \n",
      "121  ‚Çπ1,047  \n",
      "122    ‚Çπ999  \n",
      "123    ‚Çπ699  \n",
      "124  ‚Çπ1,200  \n",
      "125  ‚Çπ1,047  \n",
      "\n",
      "[126 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand name</th>\n",
       "      <th>Sneaker Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>‚Çπ297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>Lightweight Comfort Summer Trendy Premium Styl...</td>\n",
       "      <td>‚Çπ1,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Zixer</td>\n",
       "      <td>Kook N Keech Men White Faux Leather CASUAL Lac...</td>\n",
       "      <td>‚Çπ699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes Sneakers...</td>\n",
       "      <td>‚Çπ1,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Dexster Slip On IDP Sneakers For Men</td>\n",
       "      <td>‚Çπ1,047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>‚Çπ297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand name                                Sneaker Description   Price\n",
       "0            BRUTON  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...    ‚Çπ297\n",
       "1              aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ‚Çπ299\n",
       "2         Deals4you                                   Sneakers For Men    ‚Çπ399\n",
       "3              aadi                                   Sneakers For Men    ‚Çπ299\n",
       "4   U.S. POLO ASSN.  Lightweight Comfort Summer Trendy Premium Styl...  ‚Çπ1,249\n",
       "..              ...                                                ...     ...\n",
       "95            Zixer  Kook N Keech Men White Faux Leather CASUAL Lac...    ‚Çπ699\n",
       "96             PUMA  Trending Stylish Casual Outdoor Shoes Sneakers...  ‚Çπ1,200\n",
       "97             PUMA               Dexster Slip On IDP Sneakers For Men  ‚Çπ1,047\n",
       "98           BRUTON  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...    ‚Çπ297\n",
       "99             aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ‚Çπ299\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# find search input sneakers\n",
    "search_input = driver.find_elements(By.CLASS_NAME, \"Pke_EE\")\n",
    "search_input[0].send_keys('sneakers')\n",
    "\n",
    "# click search button\n",
    "search_button = driver.find_elements(By.CLASS_NAME, '_2iLD__')\n",
    "for p in search_button:\n",
    "    p.click()\n",
    "\n",
    "# create list\n",
    "time.sleep(6)\n",
    "product_brand = []\n",
    "product_description = []\n",
    "product_price = []\n",
    "\n",
    "# scrape data\n",
    "start = 1\n",
    "end = 10\n",
    "for web in range(start, end):\n",
    "    brand = driver.find_elements(By.XPATH, '//div[@class=\"syl9yP\"]')\n",
    "    desc = driver.find_elements(By.XPATH, '//a[@class=\"WKTcLC BwBZTg\"]')\n",
    "    price = driver.find_elements(By.XPATH, '//div[@class=\"Nx9bqj\"]')\n",
    "\n",
    "    # Find the minimum length among the three lists\n",
    "    min_len = min(len(brand), len(desc), len(price))\n",
    "\n",
    "    for i in range(min_len):\n",
    "        product_brand.append(brand[i].text)\n",
    "        product_description.append(desc[i].text)\n",
    "        product_price.append(price[i].text)\n",
    "\n",
    "# make Data Frame\n",
    "sneaker_df = pd.DataFrame({\n",
    "    \"Brand name\": product_brand,\n",
    "    \"Sneaker Description\": product_description,\n",
    "    \"Price\": product_price\n",
    "})\n",
    "\n",
    "print(sneaker_df)\n",
    "driver.quit()\n",
    "sneaker_df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f3ec4",
   "metadata": {},
   "source": [
    "# Q5: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU \n",
    "Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935c7cc",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title \n",
    "2. Ratings \n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc992c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Laptop Title      Product Rating  \\\n",
      "0   Lenovo IdeaPad Pro 5 Intel Evo Core Ultra 9 18...  4.0 out of 5 stars   \n",
      "1   Lenovo Yoga Slim 7 Intel Core Ultra 7 155H Bui...  4.4 out of 5 stars   \n",
      "2   (Refurbished) Lenovo ThinkPad 8th Gen Intel Co...  4.1 out of 5 stars   \n",
      "3   Lenovo IdeaPad Slim 1 Intel Core Celeron N4020...  4.6 out of 5 stars   \n",
      "4   ASUS Vivobook Go 14 (2023), 14\" (35.56 cm) FHD...  3.9 out of 5 stars   \n",
      "5   Chuwi HeroBook Pro 14.1'' Intel Celeron N4020 ...  4.0 out of 5 stars   \n",
      "6   HP Laptop 15s, AMD Ryzen 3 5300U, 15.6-inch (3...  4.2 out of 5 stars   \n",
      "7   Dell 14 Thin & Light Laptop, 12th Gen Intel Co...  4.1 out of 5 stars   \n",
      "8   Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...  4.1 out of 5 stars   \n",
      "9   HP Laptop 15s, 12th Gen Intel Core i5-1235U, 1...  4.1 out of 5 stars   \n",
      "10  Lenovo IdeaPad Slim 1 AMD Ryzen 5 5500U 15.6\" ...  3.5 out of 5 stars   \n",
      "11  Lenovo IdeaPad Slim 5 Intel Core Ultra 5 125H ...  4.1 out of 5 stars   \n",
      "12  MSI Cyborg 15 AI, Intel Core Ultra 5 125H, Bui...  3.7 out of 5 stars   \n",
      "13  ASUS VivoBook 15 (2021) Thin and Light Laptop,...  3.9 out of 5 stars   \n",
      "14  Acer Aspire Lite 12th Gen Intel Core i3-1215U ...  3.8 out of 5 stars   \n",
      "15  Walker Thin & Light Laptop, 14.1 inch (4GB Ram...  4.1 out of 5 stars   \n",
      "16  HP Laptop 15s, AMD Ryzen 5 5500U, 15.6-inch (3...  4.8 out of 5 stars   \n",
      "17  HP Laptop 15s, 12th Gen Intel Core i5-1235U, 1...  3.0 out of 5 stars   \n",
      "18  Lenovo IdeaPad Slim 3 13th Gen Intel Core i7-1...  3.9 out of 5 stars   \n",
      "19  HP Laptop 15,12th Gen Intel Core i3-1215U,15.6...  4.0 out of 5 stars   \n",
      "20  Chuwi HeroBook Pro 14.1'' Intel Celeron N4020 ...  3.9 out of 5 stars   \n",
      "21  ASUS TUF F17 Gaming Laptop, Intel Core i5-1140...  4.1 out of 5 stars   \n",
      "22  Lenovo IdeaPad Pro 5 Intel Core Ultra 7 155H B...  4.1 out of 5 stars   \n",
      "23  Bestor 4-Port USB 3.0 Hub [90¬∞/180¬∞ Degree Rot...  4.1 out of 5 stars   \n",
      "\n",
      "   Laptop Price  \n",
      "0      1,07,990  \n",
      "1      1,07,990  \n",
      "2        17,899  \n",
      "3        25,990  \n",
      "4        22,950  \n",
      "5      1,07,990  \n",
      "6        58,490  \n",
      "7        47,990  \n",
      "8        45,990  \n",
      "9        69,990  \n",
      "10       16,990  \n",
      "11       31,990  \n",
      "12       35,990  \n",
      "13       34,990  \n",
      "14       52,525  \n",
      "15       38,990  \n",
      "16       81,990  \n",
      "17       96,990  \n",
      "18       21,530  \n",
      "19       31,990  \n",
      "20       12,990  \n",
      "21       41,890  \n",
      "22       52,490  \n",
      "23       63,990  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Product Rating</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Pro 5 Intel Evo Core Ultra 9 18...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga Slim 7 Intel Core Ultra 7 155H Bui...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Refurbished) Lenovo ThinkPad 8th Gen Intel Co...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>17,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Core Celeron N4020...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook Go 14 (2023), 14\" (35.56 cm) FHD...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>22,950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chuwi HeroBook Pro 14.1'' Intel Celeron N4020 ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Laptop 15s, AMD Ryzen 3 5300U, 15.6-inch (3...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>58,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell 14 Thin &amp; Light Laptop, 12th Gen Intel Co...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>47,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>45,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i5-1235U, 1...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>69,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title      Product Rating  \\\n",
       "0  Lenovo IdeaPad Pro 5 Intel Evo Core Ultra 9 18...  4.0 out of 5 stars   \n",
       "1  Lenovo Yoga Slim 7 Intel Core Ultra 7 155H Bui...  4.4 out of 5 stars   \n",
       "2  (Refurbished) Lenovo ThinkPad 8th Gen Intel Co...  4.1 out of 5 stars   \n",
       "3  Lenovo IdeaPad Slim 1 Intel Core Celeron N4020...  4.6 out of 5 stars   \n",
       "4  ASUS Vivobook Go 14 (2023), 14\" (35.56 cm) FHD...  3.9 out of 5 stars   \n",
       "5  Chuwi HeroBook Pro 14.1'' Intel Celeron N4020 ...  4.0 out of 5 stars   \n",
       "6  HP Laptop 15s, AMD Ryzen 3 5300U, 15.6-inch (3...  4.2 out of 5 stars   \n",
       "7  Dell 14 Thin & Light Laptop, 12th Gen Intel Co...  4.1 out of 5 stars   \n",
       "8  Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...  4.1 out of 5 stars   \n",
       "9  HP Laptop 15s, 12th Gen Intel Core i5-1235U, 1...  4.1 out of 5 stars   \n",
       "\n",
       "  Laptop Price  \n",
       "0     1,07,990  \n",
       "1     1,07,990  \n",
       "2       17,899  \n",
       "3       25,990  \n",
       "4       22,950  \n",
       "5     1,07,990  \n",
       "6       58,490  \n",
       "7       47,990  \n",
       "8       45,990  \n",
       "9       69,990  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "# get webpage\n",
    "driver.get('https://www.amazon.in')\n",
    "\n",
    "#find search bar\n",
    "try:\n",
    "    search_bar=driver.find_elements(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "    search_bar[0].send_keys('Laptop')\n",
    "except ElementNotInteractableException:\n",
    "    time.sleep(3)\n",
    "    \n",
    "#click search button\n",
    "search_button=driver.find_elements(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "for button in search_button:\n",
    "    button.click()\n",
    "\n",
    "# set CPU filter intel Core i7\n",
    "filter_intel=driver.find_elements(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div/div/div/div[5]/ul[2]/span/span[8]/li/span/a/span')\n",
    "for tick in filter_intel:\n",
    "    tick.click()\n",
    "\n",
    "#click for get rating    \n",
    "rate_click=driver.find_elements(By.XPATH,'//i[@class=\"a-icon a-icon-star-small a-star-small-3-5 aok-align-bottom\"]')\n",
    "for button in rate_click:\n",
    "    button.click()\n",
    "\n",
    "#scrape Data \n",
    "lap_Title=[]\n",
    "lap_Ratings=[]\n",
    "lap_Price=[]\n",
    "start=0\n",
    "end=1\n",
    "for web in range(start,end):\n",
    "    title=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    rating=driver.find_elements(By.XPATH,'//*[@class=\"a-row a-size-small\"]//span[@aria-label][1]')\n",
    "    price=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "    \n",
    "    for i in range(len(title)):\n",
    "        lap_Title.append(title[i].text)\n",
    "        lap_Ratings.append(rating[i].get_attribute('aria-label'))\n",
    "        lap_Price.append(price[i].text)\n",
    "    \n",
    "    \n",
    "#create Data Frame\n",
    "Laptop_df = pd.DataFrame({\n",
    "    \"Laptop Title\":lap_Title,\n",
    "    \"Product Rating\":lap_Ratings,\n",
    "    \"Laptop Price\":lap_Price\n",
    "})\n",
    "\n",
    "print(Laptop_df)\n",
    "driver.quit()\n",
    "Laptop_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553ad18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
