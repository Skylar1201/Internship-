{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2503150",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857f875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ad564",
   "metadata": {},
   "source": [
    "1.Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank B) Name C) Artist D) Upload date E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63441e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list for scraping data\n",
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8ed034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "['\"Baby Shark Dance\"[7]', '\"Despacito\"[10]', '\"Johny Johny Yes Papa\"[18]', '\"Bath Song\"[19]', '\"Wheels on the Bus\"[20]', '\"See You Again\"[21]', '\"Shape of You\"[26]', '\"Phonics Song with Two Words\"[29]', '\"Uptown Funk\"[30]', '\"Gangnam Style\"[31]', '\"Learning Colors – Colorful Eggs on a Farm\"[36]', '\"Dame Tu Cosita\"[37]', '\"Axel F\"[38]', '\"Masha and the Bear – Recipe for Disaster\"[39]', '\"Baa Baa Black Sheep\"[40]', '\"Lakdi Ki Kathi\"[41]', '\"Sugar\"[42]', '\"Counting Stars\"[43]', '\"Roar\"[44]', '\"Waka Waka (This Time for Africa)\"[45]', '\"Shree Hanuman Chalisa\"[46]', '\"Humpty the train on a fruits ride\"[47]', '\"Sorry\"[48]', '\"Thinking Out Loud\"[49]', '\"Perfect\"[50]', '\"Dark Horse\"[51]', '\"Let Her Go\"[52]', '\"Faded\"[53]', '\"Girls Like You\"[54]', '\"Lean On\"[55]', '\"Baby Shark Dance\"[7]', '\"Despacito\"[10]', '\"Johny Johny Yes Papa\"[18]', '\"Bath Song\"[19]', '\"Wheels on the Bus\"[20]', '\"See You Again\"[21]', '\"Shape of You\"[26]', '\"Phonics Song with Two Words\"[29]', '\"Uptown Funk\"[30]', '\"Gangnam Style\"[31]', '\"Learning Colors – Colorful Eggs on a Farm\"[36]', '\"Dame Tu Cosita\"[37]', '\"Axel F\"[38]', '\"Masha and the Bear – Recipe for Disaster\"[39]', '\"Baa Baa Black Sheep\"[40]', '\"Lakdi Ki Kathi\"[41]', '\"Sugar\"[42]', '\"Counting Stars\"[43]', '\"Roar\"[44]', '\"Waka Waka (This Time for Africa)\"[45]', '\"Shree Hanuman Chalisa\"[46]', '\"Humpty the train on a fruits ride\"[47]', '\"Sorry\"[48]', '\"Thinking Out Loud\"[49]', '\"Perfect\"[50]', '\"Dark Horse\"[51]', '\"Let Her Go\"[52]', '\"Faded\"[53]', '\"Girls Like You\"[54]', '\"Lean On\"[55]', '\"Baby Shark Dance\"[7]', '\"Despacito\"[10]', '\"Johny Johny Yes Papa\"[18]', '\"Bath Song\"[19]', '\"Wheels on the Bus\"[20]', '\"See You Again\"[21]', '\"Shape of You\"[26]', '\"Phonics Song with Two Words\"[29]', '\"Uptown Funk\"[30]', '\"Gangnam Style\"[31]', '\"Learning Colors – Colorful Eggs on a Farm\"[36]', '\"Dame Tu Cosita\"[37]', '\"Axel F\"[38]', '\"Masha and the Bear – Recipe for Disaster\"[39]', '\"Baa Baa Black Sheep\"[40]', '\"Lakdi Ki Kathi\"[41]', '\"Sugar\"[42]', '\"Counting Stars\"[43]', '\"Roar\"[44]', '\"Waka Waka (This Time for Africa)\"[45]', '\"Shree Hanuman Chalisa\"[46]', '\"Humpty the train on a fruits ride\"[47]', '\"Sorry\"[48]', '\"Thinking Out Loud\"[49]', '\"Perfect\"[50]', '\"Dark Horse\"[51]', '\"Let Her Go\"[52]', '\"Faded\"[53]', '\"Girls Like You\"[54]', '\"Lean On\"[55]']\n"
     ]
    }
   ],
   "source": [
    "# scraping Name and Rank\n",
    "try:\n",
    "    nam=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "    for i in nam:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('-')\n",
    "print(len(Name))\n",
    "print(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18cd4309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# scraping Artist name\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('-')\n",
    "    \n",
    "    print(Artist)\n",
    "print(len(Artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5368113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# scraping Upload Date\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Upload_date.append('-')  \n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('-')\n",
    "    print(Upload_date)\n",
    "print(len(Upload_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876fe098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14.82', '8.49', '6.94', '6.79', '6.34', '6.33', '6.30', '5.90', '5.28', '5.22', '5.15', '4.72', '4.66', '4.59', '4.14', '4.11', '4.08', '4.05', '4.03', '3.99', '3.94', '3.87', '3.83', '3.79', '3.77', '3.76', '3.69', '3.66', '3.64', '3.64']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# scraping Views\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('-')\n",
    "    \n",
    "print(Views)\n",
    "print(len(Views))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639614dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Viewed Video on YouTube from Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "print('Most Viewed Video on YouTube from Wikipedia')\n",
    "Wiki_youtube_df=pd.DataFrame({\n",
    "    'Video Name':Name[:18],\n",
    "    'Uploader':Artist[:18],\n",
    "    'Views':Views[:18],\n",
    "    'Upload Date':Upload_date[:18]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02663972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the Rank as index\n",
    "Wiki_youtube_df['Rank'] = Wiki_youtube_df.index\n",
    "Wiki_youtube_df['Rank'] = range(1, len(Wiki_youtube_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa47c182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>14.82</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.49</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.94</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.79</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Wheels on the Bus\"[20]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.34</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.33</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.30</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.90</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.28</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.22</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.15</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.72</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.66</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[39]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.59</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>4.14</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[41]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>4.11</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Sugar\"[42]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.08</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Counting Stars\"[43]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>4.05</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                       Video Name  \\\n",
       "0      1                            \"Baby Shark Dance\"[7]   \n",
       "1      2                                  \"Despacito\"[10]   \n",
       "2      3                       \"Johny Johny Yes Papa\"[18]   \n",
       "3      4                                  \"Bath Song\"[19]   \n",
       "4      5                          \"Wheels on the Bus\"[20]   \n",
       "5      6                              \"See You Again\"[21]   \n",
       "6      7                               \"Shape of You\"[26]   \n",
       "7      8                \"Phonics Song with Two Words\"[29]   \n",
       "8      9                                \"Uptown Funk\"[30]   \n",
       "9     10                              \"Gangnam Style\"[31]   \n",
       "10    11  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11    12                             \"Dame Tu Cosita\"[37]   \n",
       "12    13                                     \"Axel F\"[38]   \n",
       "13    14   \"Masha and the Bear – Recipe for Disaster\"[39]   \n",
       "14    15                        \"Baa Baa Black Sheep\"[40]   \n",
       "15    16                             \"Lakdi Ki Kathi\"[41]   \n",
       "16    17                                      \"Sugar\"[42]   \n",
       "17    18                             \"Counting Stars\"[43]   \n",
       "\n",
       "                                             Uploader  Views  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  14.82   \n",
       "1                                          Luis Fonsi   8.49   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.94   \n",
       "3                          Cocomelon - Nursery Rhymes   6.79   \n",
       "4                          Cocomelon - Nursery Rhymes   6.34   \n",
       "5                                         Wiz Khalifa   6.33   \n",
       "6                                          Ed Sheeran   6.30   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.90   \n",
       "8                                         Mark Ronson   5.28   \n",
       "9                                                 Psy   5.22   \n",
       "10                                        Miroshka TV   5.15   \n",
       "11                                      Ultra Records   4.72   \n",
       "12                                         Crazy Frog   4.66   \n",
       "13                                         Get Movies   4.59   \n",
       "14                         Cocomelon - Nursery Rhymes   4.14   \n",
       "15                                       Jingle Toons   4.11   \n",
       "16                                           Maroon 5   4.08   \n",
       "17                                        OneRepublic   4.05   \n",
       "\n",
       "          Upload Date  \n",
       "0    November 2, 2020  \n",
       "1      August 4, 2017  \n",
       "2       July 10, 2017  \n",
       "3   November 24, 2012  \n",
       "4       July 16, 2010  \n",
       "5      April 14, 2010  \n",
       "6    October 25, 2009  \n",
       "7         May 2, 2009  \n",
       "8       July 17, 2008  \n",
       "9      March 15, 2008  \n",
       "10      March 1, 2008  \n",
       "11       May 19, 2006  \n",
       "12     March 12, 2006  \n",
       "13  February 18, 2006  \n",
       "14   January 21, 2006  \n",
       "15    January 9, 2006  \n",
       "16   October 31, 2005  \n",
       "17   October 29, 2005  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki_youtube_df= pd.DataFrame(Wiki_youtube_df)\n",
    "\n",
    "# Set the 'Rank' column as the first column\n",
    "Wiki_youtube_df= Wiki_youtube_df[['Rank', 'Video Name', 'Uploader', 'Views', 'Upload Date']]\n",
    "Wiki_youtube_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a3a7c",
   "metadata": {},
   "source": [
    "2.Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details: A) Series B) Place C) Date D) Time Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27aee280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45288258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get webpage\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc73e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bcci.tv home page reach out the international fixture page\n",
    "search= driver.find_element(By.XPATH, '//div[@class=\"imw-tabs international-tabs\"]/a[2]')      \n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26cbf9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the list\n",
    "Series=[]\n",
    "Place =[]\n",
    "Date =[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e2db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping series\n",
    "time.sleep(5)\n",
    "sris=driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in sris:\n",
    "    if i.text is None :\n",
    "        Series.append(\"--\") \n",
    "    else:\n",
    "        Series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15026cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping date\n",
    "time.sleep(5)\n",
    "dat=driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in dat:\n",
    "    if i.text is None :\n",
    "        Date.append(\"--\") \n",
    "    else:\n",
    "        Date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c631b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping time\n",
    "time.sleep(5)\n",
    "tim=driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in tim:\n",
    "    if i.text is None :\n",
    "        Time.append(\"--\") \n",
    "    else:\n",
    "        Time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4bc68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping place\n",
    "time.sleep(5)\n",
    "plce=driver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in plce:\n",
    "    if i.text is None :\n",
    "        Place.append(\"--\") \n",
    "    else:\n",
    "        Place.append(i.text)\n",
    "        \n",
    "#close web page\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4b872e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series: 5\n",
      "Date: 5\n",
      "Place: 5\n"
     ]
    }
   ],
   "source": [
    "# print len of all scraping Data\n",
    "print(\"Series:\",len(Series))\n",
    "print(\"Date:\",len(Date))\n",
    "#print(\"Time:\",len(Time))\n",
    "print(\"Place:\",len(Place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806ffbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India Tour Of Sri Lanka T20 Series 2024</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>28 Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India Tour Of Sri Lanka T20 Series 2024</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>30 Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India Tour Of Sri Lanka ODI Series 2024</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>2 Aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India Tour Of Sri Lanka ODI Series 2024</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>4 Aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India Tour Of Sri Lanka ODI Series 2024</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>7 Aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Series  \\\n",
       "0  India Tour Of Sri Lanka T20 Series 2024   \n",
       "1  India Tour Of Sri Lanka T20 Series 2024   \n",
       "2  India Tour Of Sri Lanka ODI Series 2024   \n",
       "3  India Tour Of Sri Lanka ODI Series 2024   \n",
       "4  India Tour Of Sri Lanka ODI Series 2024   \n",
       "\n",
       "                                     Place     Date  \n",
       "0  Pallekele International Cricket Stadium,  28 Jul  \n",
       "1  Pallekele International Cricket Stadium,  30 Jul  \n",
       "2        R Premadasa International Stadium,   2 Aug  \n",
       "3        R Premadasa International Stadium,   4 Aug  \n",
       "4        R Premadasa International Stadium,   7 Aug  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making Data Frame\n",
    "T20_df=pd.DataFrame({\n",
    "    \"Series\":Series,\n",
    "    \"Place \":Place ,\n",
    "    \"Date\":Date,\n",
    "    })\n",
    "T20_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5a575",
   "metadata": {},
   "source": [
    "3.Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details: A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d25223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fac2f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url=\"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bac793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click On Ecomoy Option\n",
    "time.sleep(3)\n",
    "economy = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/button')     \n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ddfcf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on India Option\n",
    "time.sleep(3)\n",
    "try:\n",
    "    India = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "    India.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception raised\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40bf5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on GDP on Indian States in Indian States\n",
    "time.sleep(3)\n",
    "gdp = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')      \n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87a69bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scrapping List\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_22_23=[]\n",
    "GSDP_23_24=[]\n",
    "Share_21_22=[]\n",
    "GDP=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d475b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank \n",
    "time.sleep(5)\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH, \"//td[@class='data1']\")\n",
    "    for i in ranks:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0df39d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping State\n",
    "time.sleep(5)\n",
    "try:\n",
    "    states=driver.find_elements(By.XPATH, \"//td[@class='name']\")\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "     State.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0299d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP for 22-23 because here 18 _19 not showing\n",
    "time.sleep(5)\n",
    "try:\n",
    "    gdp_23=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdp_23:\n",
    "        GSDP_22_23.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_22_23.append(\"--\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43ab6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP 23-24 because here not shown 19_ 20\n",
    "time.sleep(5)\n",
    "try:\n",
    "    gdp_24=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in gdp_24:\n",
    "        GSDP_23_24.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_23_24.append(\"--\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a294016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the Share for 21_22 here also not shown 18 _ 19\n",
    "time.sleep(5)\n",
    "try:\n",
    "    shres=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in shres:\n",
    "        Share_21_22.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share_21_22.append(\"--\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cc5c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GDP\n",
    "time.sleep(5)\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[7]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        GDP.append(\"--\") \n",
    "\n",
    "# Close web page\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "906987b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank : 68\n",
      "state : 68\n",
      "GSDP for 22 -23 : 33\n",
      "GSDP for 23 -24 : 33\n",
      "Share for 21 - 22 : 33\n",
      "GDP : 33\n"
     ]
    }
   ],
   "source": [
    "# print of all scrapping data\n",
    "print(\"Rank :\",len(Rank))\n",
    "\n",
    "print(\"state :\",len(State))\n",
    "\n",
    "print(\"GSDP for 22 -23 :\",len(GSDP_22_23))\n",
    "\n",
    "print(\"GSDP for 23 -24 :\",len(GSDP_23_24))\n",
    "\n",
    "print(\"Share for 21 - 22 :\",len(Share_21_22))\n",
    "\n",
    "print(\"GDP :\",len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eac33246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Rank</th>\n",
       "      <th>State Names</th>\n",
       "      <th>GSDP_22_23</th>\n",
       "      <th>GSDP_23_24</th>\n",
       "      <th>Share_21_22</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>934,542</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>881,336</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>984,055</td>\n",
       "      <td>868,905</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>753,177</td>\n",
       "      <td>662,886</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>676,164</td>\n",
       "      <td>617,192</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>411,454</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>464,399</td>\n",
       "      <td>410,525</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>303,781</td>\n",
       "      <td>267,143</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>224,226</td>\n",
       "      <td>193,352</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>191,728</td>\n",
       "      <td>172,162</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>93,672</td>\n",
       "      <td>84,266</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>54,285</td>\n",
       "      <td>46,096</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>49,643</td>\n",
       "      <td>43,810</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>39,630</td>\n",
       "      <td>34,775</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>35,643</td>\n",
       "      <td>31,038</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Rank                State Names GSDP_22_23 GSDP_23_24 Share_21_22  \\\n",
       "0           1                Maharashtra          -  3,108,022      13.17%   \n",
       "1           2                 Tamil Nadu  2,364,514  2,071,286       8.78%   \n",
       "2           3                  Karnataka  2,269,995  1,978,094       8.38%   \n",
       "3           4              Uttar Pradesh  2,258,040  1,975,595       8.37%   \n",
       "4           5                    Gujarat  2,230,609  1,928,683       8.17%   \n",
       "5           6                West Bengal  1,531,758  1,329,238       5.63%   \n",
       "6           7                  Rajasthan  1,365,849  1,193,489       5.06%   \n",
       "7           8             Andhra Pradesh  1,303,524  1,148,471       4.87%   \n",
       "8           9                  Telangana  1,308,034  1,124,204       4.76%   \n",
       "9          10             Madhya Pradesh  1,246,471  1,092,964       4.63%   \n",
       "10         11                     Kerala  1,046,188    934,542       3.96%   \n",
       "11         12                      Delhi  1,014,688    881,336       3.73%   \n",
       "12         13                    Haryana    984,055    868,905       3.68%   \n",
       "13         14                     Odisha    753,177    662,886       2.81%   \n",
       "14         15                      Bihar    751,396    650,302       2.76%   \n",
       "15         16                     Punjab    676,164    617,192       2.62%   \n",
       "16         17                      Assam    493,167    411,454       1.74%   \n",
       "17         18               Chhattisgarh    464,399    410,525       1.74%   \n",
       "18         19                  Jharkhand    393,722    358,863       1.52%   \n",
       "19         20                Uttarakhand    303,781    267,143       1.13%   \n",
       "20         21            Jammu & Kashmir    224,226    193,352       0.82%   \n",
       "21         22           Himachal Pradesh    191,728    172,162       0.73%   \n",
       "22         23                        Goa     93,672     84,266       0.36%   \n",
       "23         24                    Tripura     72,636     62,550       0.27%   \n",
       "24         25                 Chandigarh     54,285     46,096       0.20%   \n",
       "25         26                 Puducherry     49,643     43,810       0.19%   \n",
       "26         27                  Meghalaya     42,697     38,785       0.16%   \n",
       "27         28                     Sikkim     42,756     37,557       0.16%   \n",
       "28         29                    Manipur          -     36,594       0.16%   \n",
       "29         30          Arunachal Pradesh     39,630     34,775       0.15%   \n",
       "30         31                   Nagaland     35,643     31,038       0.13%   \n",
       "31         32                    Mizoram          -     27,824       0.12%   \n",
       "32         33  Andaman & Nicobar Islands          -     10,371       0.04%   \n",
       "\n",
       "        GDP  \n",
       "0   414.928  \n",
       "1   276.522  \n",
       "2   264.080  \n",
       "3   263.747  \n",
       "4   257.484  \n",
       "5   177.456  \n",
       "6   159.334  \n",
       "7   153.324  \n",
       "8   150.084  \n",
       "9   145.913  \n",
       "10  124.764  \n",
       "11  117.660  \n",
       "12  116.001  \n",
       "13   88.497  \n",
       "14   86.817  \n",
       "15   82.397  \n",
       "16   54.930  \n",
       "17   54.806  \n",
       "18   47.909  \n",
       "19   35.664  \n",
       "20   25.813  \n",
       "21   22.984  \n",
       "22   11.250  \n",
       "23    8.351  \n",
       "24    6.154  \n",
       "25    5.849  \n",
       "26    5.178  \n",
       "27    5.014  \n",
       "28    4.885  \n",
       "29    4.643  \n",
       "30    4.144  \n",
       "31    3.715  \n",
       "32    1.385  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making Data Frame\n",
    "state_GDP_df=pd.DataFrame({\n",
    "    \"State Rank\":Rank[:33],\n",
    "    \"State Names\":State[:33],\n",
    "    \"GSDP_22_23\":GSDP_22_23[:33],\n",
    "    \"GSDP_23_24\":GSDP_23_24[:33],\n",
    "    \"Share_21_22\":Share_21_22[:33],\n",
    "    \"GDP\":GDP[:33]\n",
    "})\n",
    "state_GDP_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b3215",
   "metadata": {},
   "source": [
    "4.Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used \n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1dfc936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a319b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open web page\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://github.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8cf74b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Lists\n",
    "R_title=[]\n",
    "R_discr=[]\n",
    "contributers=[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09b4577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Open Source\n",
    "explore = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/button')      \n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "797d0b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Raised Message: element not interactable\n",
      "  (Session info: chrome=126.0.6478.183)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7A31AEEB2+31554]\n",
      "\t(No symbol) [0x00007FF7A3127EE9]\n",
      "\t(No symbol) [0x00007FF7A2FE8559]\n",
      "\t(No symbol) [0x00007FF7A30397C2]\n",
      "\t(No symbol) [0x00007FF7A302C151]\n",
      "\t(No symbol) [0x00007FF7A305D02A]\n",
      "\t(No symbol) [0x00007FF7A302BA76]\n",
      "\t(No symbol) [0x00007FF7A305D240]\n",
      "\t(No symbol) [0x00007FF7A307C977]\n",
      "\t(No symbol) [0x00007FF7A305CDD3]\n",
      "\t(No symbol) [0x00007FF7A302A33B]\n",
      "\t(No symbol) [0x00007FF7A302AED1]\n",
      "\tGetHandleVerifier [0x00007FF7A34B8B2D+3217341]\n",
      "\tGetHandleVerifier [0x00007FF7A3505AF3+3532675]\n",
      "\tGetHandleVerifier [0x00007FF7A34FB0F0+3489152]\n",
      "\tGetHandleVerifier [0x00007FF7A325E786+750614]\n",
      "\t(No symbol) [0x00007FF7A313376F]\n",
      "\t(No symbol) [0x00007FF7A312EB24]\n",
      "\t(No symbol) [0x00007FF7A312ECB2]\n",
      "\t(No symbol) [0x00007FF7A311E17F]\n",
      "\tBaseThreadInitThunk [0x00007FFA9BB3257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFA9CD0AF28+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#click on Trending repository\n",
    "try:\n",
    "    trending = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/div/div[3]/ul/li[2]/a')  \n",
    "    trending.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36109383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Repositor_Name \n",
    "r_nam=driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in r_nam:\n",
    "    if i.text is None :\n",
    "        R_title.append(\"--\") \n",
    "    else:\n",
    "        R_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "331e0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Description \n",
    "r_des=driver.find_elements(By.XPATH, '//article[@class=\"Box-row\"]/p')\n",
    "for i in r_des:\n",
    "    if i.text is None :\n",
    "        R_discr.append(\"--\") \n",
    "    else:\n",
    "        R_discr.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b869edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Contribution Count\n",
    "contr=driver.find_elements(By.XPATH, \"//a[@class='Link Link--muted d-inline-block mr-3'][2]\")\n",
    "for i in contr:\n",
    "    if i.text is None :\n",
    "        contributers.append(\"--\") \n",
    "    else:\n",
    "        contributers.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22e760a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Language\n",
    "lang=driver.find_elements(By.XPATH, \"//span[@itemprop='programmingLanguage']\")\n",
    "for i in lang:\n",
    "    if i.text is None :\n",
    "        Language.append(\"--\") \n",
    "    else:\n",
    "        Language.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c684148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripository Titles: 0\n",
      "Ripository Description: 0\n",
      "Contributors Count: 0\n",
      "Language Used: 0\n"
     ]
    }
   ],
   "source": [
    "# check length of all scraping data\n",
    "print(\"Ripository Titles:\", len(R_title))\n",
    "print(\"Ripository Description:\", len(R_discr))\n",
    "print(\"Contributors Count:\", len(contributers))\n",
    "print(\"Language Used:\",len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d29c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ripository Tiles</th>\n",
       "      <th>Ripository Description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Ripository Tiles, Ripository Description, Contributors count, Language Used]\n",
       "Index: []"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making Data Frme\n",
    "trending_ripository_df=pd.DataFrame({\n",
    "    \"Ripository Tiles\":R_title,\n",
    "    \"Ripository Description\":R_discr,\n",
    "    \"Contributors count\":contributers,\n",
    "    \"Language Used\":Language})\n",
    "trending_ripository_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "64fa74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa134fe6",
   "metadata": {},
   "source": [
    "5.Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details: A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "88d0c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c25f6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the web page\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5102fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from home page click on chart option by code\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    explore_chart=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "    explore_chart.click()\n",
    "except NoSuchElementException:\n",
    "    driver.get(explore_chart.get_attribute('href'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "31ac2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raised Exception Message: element click intercepted: Element is not clickable at point (138, 3063)\n",
      "  (Session info: chrome=126.0.6478.183)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7A31AEEB2+31554]\n",
      "\t(No symbol) [0x00007FF7A3127EE9]\n",
      "\t(No symbol) [0x00007FF7A2FE872A]\n",
      "\t(No symbol) [0x00007FF7A304012E]\n",
      "\t(No symbol) [0x00007FF7A303DAF2]\n",
      "\t(No symbol) [0x00007FF7A303AF8B]\n",
      "\t(No symbol) [0x00007FF7A303A156]\n",
      "\t(No symbol) [0x00007FF7A302C151]\n",
      "\t(No symbol) [0x00007FF7A305D02A]\n",
      "\t(No symbol) [0x00007FF7A302BA76]\n",
      "\t(No symbol) [0x00007FF7A305D240]\n",
      "\t(No symbol) [0x00007FF7A307C977]\n",
      "\t(No symbol) [0x00007FF7A305CDD3]\n",
      "\t(No symbol) [0x00007FF7A302A33B]\n",
      "\t(No symbol) [0x00007FF7A302AED1]\n",
      "\tGetHandleVerifier [0x00007FF7A34B8B2D+3217341]\n",
      "\tGetHandleVerifier [0x00007FF7A3505AF3+3532675]\n",
      "\tGetHandleVerifier [0x00007FF7A34FB0F0+3489152]\n",
      "\tGetHandleVerifier [0x00007FF7A325E786+750614]\n",
      "\t(No symbol) [0x00007FF7A313376F]\n",
      "\t(No symbol) [0x00007FF7A312EB24]\n",
      "\t(No symbol) [0x00007FF7A312ECB2]\n",
      "\t(No symbol) [0x00007FF7A311E17F]\n",
      "\tBaseThreadInitThunk [0x00007FFA9BB3257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFA9CD0AF28+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clicking on hot 100 option by codes\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    hot_100=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[3]/div/div/div[2]/div/div[1]/a/span\")\n",
    "    hot_100.click()\n",
    "except NoSuchElementException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "except ElementClickInterceptedException as e:\n",
    "    print(\"Raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fdc585d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list for store scraoing data\n",
    "Song_name=[]\n",
    "Artist_name = []\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c62ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Song name\n",
    "try:\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3'):\n",
    "        Song_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song_name.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "682efd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Artist name\n",
    "try:\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/span'):\n",
    "        Artist_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist_name.append('-')\n",
    "Artist_name=Artist_name[0:-1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df361a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Last_Week Rank\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]/div/ul/li/ul/li[4]/span'):\n",
    "        Last_week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_week_rank.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4df61476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the peak rank\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]/div/ul/li/ul/li[5]/span'):\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96d77e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the week on board\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]/div/ul/li/ul/li[6]/span'):\n",
    "        Weeks_on_board.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_on_board.append('-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1c95fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close wepage\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b893c048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 0\n",
      "Artist 0\n",
      "Week Rank 0\n",
      "Peak rank 0\n",
      "week on Boards 0\n"
     ]
    }
   ],
   "source": [
    "# check the len of all scrapping data\n",
    "print(\"Song\",len(Song_name))\n",
    "print(\"Artist\",len(Artist_name))\n",
    "print(\"Week Rank\",len(Last_week_rank))\n",
    "print(\"Peak rank\",len(Peak_rank))\n",
    "print(\"week on Boards\",len(Weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c197724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Song_Name, Artist_Name, Last_week_rank, Peak Rank, Weeks_on_chart]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making The data frame\n",
    "Hot_100_song_df=pd.DataFrame({'Song_Name':Song_name,\n",
    "                'Artist_Name':Artist_name,\n",
    "                'Last_week_rank':Last_week_rank,\n",
    "                'Peak Rank':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks_on_board})\n",
    "Hot_100_song_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afda425",
   "metadata": {},
   "source": [
    "6.Scrape the details of Highest selling novels. A) Book name B) Author name C) Volumes sold D) Publisher E) Genre Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "193c66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9b1f7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run webpage\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea85195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f698ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Book_name \n",
    "try:\n",
    "    time.sleep(3)\n",
    "    b_nam=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "    for i in b_nam:\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Book_name.append(\"Not Present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "deeea5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Author_name\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    Auth=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "    for i in Auth:\n",
    "        Author_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Author_name.append(\"Not Present\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4182ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Volumes_sold \n",
    "try:\n",
    "    time.sleep(3)\n",
    "    volum=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "    for i in volum:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Volumes_sold.append(\"Not Present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76425072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Publisher\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    publice=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "    for i in publice:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Publisher.append(\"Not Present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ffda02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Genre \n",
    "try:\n",
    "    time.sleep(3)\n",
    "    gen=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "    for i in gen:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Genre.append(\"Not Present\")\n",
    "    \n",
    "#close web page\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "57a77931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Name 100\n",
      "Author Name 100\n",
      "Volume Sold 100\n",
      "Publisher 100\n",
      "Genre 100\n"
     ]
    }
   ],
   "source": [
    "#check length of all scrapping data\n",
    "print(\"Book Name\",len(Book_name))\n",
    "print(\"Author Name\",len(Author_name))\n",
    "print(\"Volume Sold\",len(Volumes_sold))\n",
    "print(\"Publisher\",len(Publisher))\n",
    "print(\"Genre\",len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "59f4c138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create data Frame\n",
    "Novel_df=pd.DataFrame({\n",
    "    \"Book Name\":Book_name,\n",
    "    \"Author Name\":Author_name,\n",
    "    \"Volume Sold\":Volumes_sold,\n",
    "    \"Publisher\":Publisher,\n",
    "    \"Genre\":Genre})\n",
    "\n",
    "Novel_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d092f",
   "metadata": {},
   "source": [
    "7.Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ff175263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cea6a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get web page\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.imdb.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ad5ec62c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <label aria-haspopup=\"true\" id=\"imdbHeader-navDrawerOpen\" class=\"ipc-responsive-button ipc-btn--theme-baseAlt ipc-responsive-button--transition-l ipc-btn--on-textPrimary ipc-responsive-button--single-padding sc-eJobrH kyvUMk hamburger__icon\" role=\"button\" tabindex=\"0\" aria-label=\"Open Navigation Drawer\" aria-disabled=\"false\" for=\"imdbHeader-navDrawer\">...</label> is not clickable at point (138, 28). Other element would receive the click: <div class=\"drawer__panel\" role=\"presentation\" aria-hidden=\"false\" data-testid=\"panel\">...</div>\n  (Session info: chrome=126.0.6478.183)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7A31AEEB2+31554]\n\t(No symbol) [0x00007FF7A3127EE9]\n\t(No symbol) [0x00007FF7A2FE872A]\n\t(No symbol) [0x00007FF7A304012E]\n\t(No symbol) [0x00007FF7A303DAF2]\n\t(No symbol) [0x00007FF7A303AF8B]\n\t(No symbol) [0x00007FF7A303A156]\n\t(No symbol) [0x00007FF7A302C151]\n\t(No symbol) [0x00007FF7A305D02A]\n\t(No symbol) [0x00007FF7A302BA76]\n\t(No symbol) [0x00007FF7A305D240]\n\t(No symbol) [0x00007FF7A307C977]\n\t(No symbol) [0x00007FF7A305CDD3]\n\t(No symbol) [0x00007FF7A302A33B]\n\t(No symbol) [0x00007FF7A302AED1]\n\tGetHandleVerifier [0x00007FF7A34B8B2D+3217341]\n\tGetHandleVerifier [0x00007FF7A3505AF3+3532675]\n\tGetHandleVerifier [0x00007FF7A34FB0F0+3489152]\n\tGetHandleVerifier [0x00007FF7A325E786+750614]\n\t(No symbol) [0x00007FF7A313376F]\n\t(No symbol) [0x00007FF7A312EB24]\n\t(No symbol) [0x00007FF7A312ECB2]\n\t(No symbol) [0x00007FF7A311E17F]\n\tBaseThreadInitThunk [0x00007FFA9BB3257D+29]\n\tRtlUserThreadStart [0x00007FFA9CD0AF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     menu\u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipc-page-content-container ipc-page-content-container--center navbar__inner\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/label[1]\u001b[39m\u001b[38;5;124m'\u001b[39m)      \n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmenu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoSuchElementException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraised Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <label aria-haspopup=\"true\" id=\"imdbHeader-navDrawerOpen\" class=\"ipc-responsive-button ipc-btn--theme-baseAlt ipc-responsive-button--transition-l ipc-btn--on-textPrimary ipc-responsive-button--single-padding sc-eJobrH kyvUMk hamburger__icon\" role=\"button\" tabindex=\"0\" aria-label=\"Open Navigation Drawer\" aria-disabled=\"false\" for=\"imdbHeader-navDrawer\">...</label> is not clickable at point (138, 28). Other element would receive the click: <div class=\"drawer__panel\" role=\"presentation\" aria-hidden=\"false\" data-testid=\"panel\">...</div>\n  (Session info: chrome=126.0.6478.183)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7A31AEEB2+31554]\n\t(No symbol) [0x00007FF7A3127EE9]\n\t(No symbol) [0x00007FF7A2FE872A]\n\t(No symbol) [0x00007FF7A304012E]\n\t(No symbol) [0x00007FF7A303DAF2]\n\t(No symbol) [0x00007FF7A303AF8B]\n\t(No symbol) [0x00007FF7A303A156]\n\t(No symbol) [0x00007FF7A302C151]\n\t(No symbol) [0x00007FF7A305D02A]\n\t(No symbol) [0x00007FF7A302BA76]\n\t(No symbol) [0x00007FF7A305D240]\n\t(No symbol) [0x00007FF7A307C977]\n\t(No symbol) [0x00007FF7A305CDD3]\n\t(No symbol) [0x00007FF7A302A33B]\n\t(No symbol) [0x00007FF7A302AED1]\n\tGetHandleVerifier [0x00007FF7A34B8B2D+3217341]\n\tGetHandleVerifier [0x00007FF7A3505AF3+3532675]\n\tGetHandleVerifier [0x00007FF7A34FB0F0+3489152]\n\tGetHandleVerifier [0x00007FF7A325E786+750614]\n\t(No symbol) [0x00007FF7A313376F]\n\t(No symbol) [0x00007FF7A312EB24]\n\t(No symbol) [0x00007FF7A312ECB2]\n\t(No symbol) [0x00007FF7A311E17F]\n\tBaseThreadInitThunk [0x00007FFA9BB3257D+29]\n\tRtlUserThreadStart [0x00007FFA9CD0AF28+40]\n"
     ]
    }
   ],
   "source": [
    "# click on menu\n",
    "try:\n",
    "    menu= driver.find_element(By.XPATH, '//div[@class=\"ipc-page-content-container ipc-page-content-container--center navbar__inner\"]/label[1]')      \n",
    "    menu.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ec0eb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # click on Most Popular Tv Shows\n",
    "try:\n",
    "    tv_shows= driver.find_element(By.XPATH, '/html/body/div[2]/nav/div[2]/aside[1]/div/div[2]/div/div[2]/div[1]/span/div/div/ul/a[3]/span')      \n",
    "    tv_shows.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6e0ef4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making lists for store the scraping data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9aeb4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Name\n",
    "try:\n",
    "    nam=driver.find_elements(By.XPATH, '//a[@class=\"ipc-title-link-wrapper\"]')\n",
    "    for i in nam:\n",
    "        if i.text is None :\n",
    "            Name.append(\"--\")\n",
    "        else:\n",
    "            Name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0c03f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Year_span     \n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-7 btCcOY cli-title-metadata\"]/span[1]')\n",
    "    for i in year:\n",
    "        if i.text is None :\n",
    "            Year_span.append(\"--\")     \n",
    "        else:\n",
    "            Year_span.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19d0efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Ratings\n",
    "try:\n",
    "    rate=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star--rating\"]')\n",
    "    for i in rate:\n",
    "        if i.text is None :           \n",
    "            Ratings.append(\"--\")      \n",
    "        else:\n",
    "            Ratings.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e4a9f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Votes \n",
    "try:\n",
    "    vot=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star--voteCount\"]')\n",
    "    for i in vot:\n",
    "        if i.text is None :\n",
    "            Votes.append(\"--\") \n",
    "        else:\n",
    "            Votes.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e842a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Genre\n",
    "try:\n",
    "    genr=driver.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-7 btCcOY cli-title-metadata\"]/span[3]')\n",
    "    for i in genr:\n",
    "        if i.text is None :\n",
    "            Genres.append(\"--\") \n",
    "        else:\n",
    "            Genres.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "402025c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the RunTime\n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-7 btCcOY cli-title-metadata\"]/span[2]')\n",
    "    for i in runtime:\n",
    "        if i.text is None :\n",
    "            Run_time.append(\"--\") \n",
    "        else:\n",
    "            Run_time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "91949b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2849b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Movies 108\n",
      "Year of Span 100\n",
      "Ratings Of Movies 99\n",
      "Votes 99\n",
      "Genres 96\n",
      "Run Time 200\n"
     ]
    }
   ],
   "source": [
    "# print the length of all scrapping data\n",
    "print(\"Name of Movies\",len(Name))\n",
    "print(\"Year of Span\",len(Year_span))\n",
    "print(\"Ratings Of Movies\",len(Ratings))\n",
    "print(\"Votes\",len(Votes))\n",
    "print(\"Genres\",len(Genres))\n",
    "print(\"Run Time\",len(Run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "904447cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Movies</th>\n",
       "      <th>Year of Span</th>\n",
       "      <th>Ratings Of Movies</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Boys</td>\n",
       "      <td>2019–</td>\n",
       "      <td>8.7</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>40 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House of the Dragon</td>\n",
       "      <td>2022–</td>\n",
       "      <td>8.4</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>20 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Bear</td>\n",
       "      <td>2022–</td>\n",
       "      <td>8.6</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>29 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Acolyte</td>\n",
       "      <td>2024–</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>8 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Presumed Innocent</td>\n",
       "      <td>2024</td>\n",
       "      <td>7.8</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>9 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The White Lotus</td>\n",
       "      <td>2021–2025</td>\n",
       "      <td>8.6</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>14 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The X-Files</td>\n",
       "      <td>1993–2018</td>\n",
       "      <td>7.2</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>217 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Under the Bridge</td>\n",
       "      <td>2024</td>\n",
       "      <td>8.6</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>8 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Sons of Anarchy</td>\n",
       "      <td>2008–2014</td>\n",
       "      <td>7.9</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>92 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Umbrella Academy</td>\n",
       "      <td>2019–2024</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>36 eps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name of Movies Year of Span Ratings Of Movies Genres Run Time\n",
       "0               The Boys        2019–               8.7  TV-MA   40 eps\n",
       "1    House of the Dragon        2022–               8.4  TV-MA   20 eps\n",
       "2               The Bear        2022–               8.6  TV-MA   29 eps\n",
       "3            The Acolyte        2024–               4.0  TV-14    8 eps\n",
       "4      Presumed Innocent         2024               7.8  TV-MA    9 eps\n",
       "..                   ...          ...               ...    ...      ...\n",
       "91       The White Lotus    2021–2025               8.6  TV-14   14 eps\n",
       "92           The X-Files    1993–2018               7.2  TV-14  217 eps\n",
       "93      Under the Bridge         2024               8.6  TV-14    8 eps\n",
       "94       Sons of Anarchy    2008–2014               7.9  TV-14   92 eps\n",
       "95  The Umbrella Academy    2019–2024               8.0  TV-MA   36 eps\n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make Data frame of Popular Tv shows\n",
    "Popular_Tv_shows_df=pd.DataFrame({\n",
    "    \"Name of Movies\":Name[:96],\n",
    "    \"Year of Span\":Year_span[:96],\n",
    "    \"Ratings Of Movies\":Ratings[:96],\n",
    "    \"Genres\":Genres[:96],\n",
    "    \"Run Time\":Run_time[:96]\n",
    "})\n",
    "\n",
    "Popular_Tv_shows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1376938",
   "metadata": {},
   "source": [
    "8.Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You have to find the following details: A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year Note: - from the home page you have to go to the Show All Dataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fd7696e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import regex as re\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "33e77aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the web page \n",
    "driver=webdriver.Chrome()\n",
    "url=\"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "66490be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all data set throgh codes\n",
    "try :\n",
    "    time.sleep(3)\n",
    "    all_dataset= driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')      \n",
    "    all_dataset.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bba6a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the Lists for storing Data\n",
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Attribute_type=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5790a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Dataset_Name\n",
    "\n",
    "data_nam=driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in data_nam:\n",
    "    if i.text is None :\n",
    "        Dataset_Name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e3a06f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Data_Type \n",
    "\n",
    "data_typ=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]')\n",
    "for i in data_typ:\n",
    "    if i.text is None :\n",
    "        Data_Type.append(\"--\") \n",
    "    else:\n",
    "        Data_Type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d098e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Task\n",
    "\n",
    "tsk=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]')\n",
    "for i in tsk:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bf6af64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the No_of_Instances \n",
    "\n",
    "instance=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]')\n",
    "for i in instance:\n",
    "    if i.text is None :\n",
    "        No_of_Instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_Instances.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c05464b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the No_of_Attribute\n",
    "\n",
    "num_atrribute=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]')\n",
    "for i in num_atrribute:\n",
    "    if i.text is None :\n",
    "        No_of_Attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_Attribute.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb9bbabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Name 10\n",
      "Dataset Type 10\n",
      "Task 10\n",
      "Num. of Instances 10\n",
      "Num. of attributes 10\n"
     ]
    }
   ],
   "source": [
    "# check length of scrapping data\n",
    "print(\"Datasets Name\",len(Dataset_Name))\n",
    "print(\"Dataset Type\",len(Data_Type))\n",
    "print(\"Task\",len(Task))\n",
    "print(\"Num. of Instances\",len(No_of_Instances))\n",
    "print(\"Num. of attributes\",len(No_of_Attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "feb3a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the dataset URL\n",
    "urls_dataset=[]\n",
    "time.sleep(3)\n",
    "url_dataset=driver.find_elements(By.XPATH,'//div[@class=\"h-12 w-12 rounded\"]/a')\n",
    "for i in url_dataset:\n",
    "    urls_dataset.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a862bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the attribute type and year\n",
    "for i in urls_dataset:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        a_type=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]//div[4]//p')\n",
    "        for a in a_type:\n",
    "            Attribute_type.append(a.text)\n",
    "            \n",
    "        years=driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div[2]/h2')\n",
    "        for a in years:\n",
    "            Year.append(a.text)\n",
    "            \n",
    "    except NoSuchElementException as e:\n",
    "        Attribute_type.append('No Present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "200d085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Datasets 10\n",
      "Attribute Type 10\n",
      "years 10\n",
      "URL Datasets 10\n",
      "Attribute Type 10\n",
      "years 10\n"
     ]
    }
   ],
   "source": [
    "# check length again\n",
    "print(\"URL Datasets\",len(urls_dataset))\n",
    "print(\"Attribute Type\",len(Attribute_type))\n",
    "print(\"years\",len(Year))\n",
    "print(\"URL Datasets\",len(urls_dataset))\n",
    "print(\"Attribute Type\",len(Attribute_type))\n",
    "print(\"years\",len(Year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "39494685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close web page\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "471b2507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datasets Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Donated on 9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>Donated on 8/13/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Donated on 6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 10/6/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Donated on 2/13/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Datasets Name     Data Type  \\\n",
       "0                                  Iris       Tabular   \n",
       "1                              Dry Bean  Multivariate   \n",
       "2                         Heart Disease  Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)  Multivariate   \n",
       "4                                Raisin  Multivariate   \n",
       "5                                 Adult  Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Multivariate   \n",
       "7                                  Wine       Tabular   \n",
       "8                          Wine Quality  Multivariate   \n",
       "9                        Bank Marketing  Multivariate   \n",
       "\n",
       "                         Task   No_of_Instances No_of_Attribute  \\\n",
       "0              Classification     150 Instances      4 Features   \n",
       "1              Classification  13.61K Instances     16 Features   \n",
       "2              Classification     303 Instances     13 Features   \n",
       "3              Classification   3.81K Instances      7 Features   \n",
       "4              Classification     900 Instances      8 Features   \n",
       "5              Classification  48.84K Instances     14 Features   \n",
       "6              Classification     569 Instances     30 Features   \n",
       "7              Classification     178 Instances     13 Features   \n",
       "8  Classification, Regression    4.9K Instances     12 Features   \n",
       "9              Classification  45.21K Instances     17 Features   \n",
       "\n",
       "               Attribute_type                   Year  \n",
       "0                        Real   Donated on 6/30/1988  \n",
       "1               Integer, Real   Donated on 9/13/2020  \n",
       "2  Categorical, Integer, Real   Donated on 6/30/1988  \n",
       "3                        Real   Donated on 10/5/2019  \n",
       "4               Real, Integer   Donated on 8/13/2023  \n",
       "5        Categorical, Integer   Donated on 4/30/1996  \n",
       "6                        Real  Donated on 10/31/1995  \n",
       "7               Integer, Real   Donated on 6/30/1991  \n",
       "8                        Real   Donated on 10/6/2009  \n",
       "9        Categorical, Integer   Donated on 2/13/2012  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make DataFrame\n",
    "All_datasets_df=pd.DataFrame({\n",
    "    \"Datasets Name\":Dataset_Name,\n",
    "    \"Data Type\":Data_Type,\n",
    "    \"Task\":Task,\n",
    "    \"No_of_Instances\":No_of_Instances,\n",
    "    \"No_of_Attribute\":No_of_Attribute,\n",
    "    \"Attribute_type\":Attribute_type,\n",
    "    \"Year\":Year})\n",
    "\n",
    "All_datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745fbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
